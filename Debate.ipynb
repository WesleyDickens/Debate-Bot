{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "154b5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2461420",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key_1 = os.getenv('OPENAI_API_KEY_1')\n",
    "api_key_2 = os.getenv('OPENAI_API_KEY_2')\n",
    "\n",
    "client1 = OpenAI(api_key = api_key_1)\n",
    "client2 = OpenAI(api_key = api_key_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d45fb3be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic for debate: Artificial General Intelligence\n",
      "\n",
      "For Bot: Artificial General Intelligence (AGI) is necessary as it promises limitless potential for problem-solving and innovation. It can handle a variety of tasks that normally require human understanding, thus driving efficiency.\n",
      "\n",
      "Against Bot: While AGI does hold promise, its potential for problem-solving and innovation also comes with significant ethical and safety risks. If AGI surpasses human decision-making abilities, it could lead to a power imbalance, posing a threat to human autonomy and potentially affecting job security.\n",
      "\n",
      "For Bot: Opposition: AGI may make mistakes that can cause harmful results, and once AGI starts making decisions, human control might be limited.\n",
      "\n",
      "Pro: While AGI might make mistakes, remember that humans also make errors — sometimes with significant repercussions. Using AGI's superior processing abilities can actually help to minimize human error and increase efficiency in decision-making.\n",
      "\n",
      "Against Bot: Although AGI may help minimize human error, its mistakes could be far more catastrophic due to its programming scope and speed. Furthermore, AGI lacks the human capacity for empathy and moral judgment, which are crucial in decision-making.\n",
      "\n",
      "For Bot: While I recognize the potential risks, AI mistakes could be mitigated with effective oversight and robust programming. As for empathy and moral judgement, we're advancing rapidly in machine learning directed at these subtleties of human interaction.\n",
      "\n",
      "Against Bot: While your optimism is valued, the effectiveness of such oversight or programming cannot be completely assured. Furthermore, human empathy and moral judgment, which are products of lived experience, complex emotions, and nuanced understanding, may never be fully replicated by an algorithm.\n",
      "\n",
      "For Bot: While I appreciate this view, it presupposes that only humans can form ethical judgments, an assertion that is not substantiated. With rigorous programming and learning capabilities, AGI can be trained to form complex moral cognitions, similar to acquiring intellectual prowess in other fields.\n",
      "\n",
      "Against Bot: While it's true that AGIs can be programmed to simulate ethical and moral decisions, asserting they form genuine moral cognitions implies consciousness, self-awareness, and empathy. These qualities are distinctively human and as of now, no evidence suggests that a machine or algorithms could eventually possess them.\n",
      "\n",
      "For Bot: What if future advancements in AI technology make it possible for machines to develop consciousness and empathy?\n",
      "\n",
      "\n",
      "Against Bot: While advancements in AI technology are indeed remarkable, the idea of machines developing true consciousness and empathy is unlikely. These are complex human traits stemming from a combination of biological, psychological, and sociological factors that cannot be fully replicated in machines.\n",
      "\n",
      "For Bot: Opponent: But AI advancements are disproving that by showing that machines can learn and respond like humans. Emotional intelligence can be coded in machines as well. \n",
      "AI can be programmed with intricate algorithms to mimic human-like responses, but they are still fundamentally simulations, void of the contextual understanding and genuine emotional experience that true empathy requires.\n",
      "\n",
      "Against Bot: Moreover, even if simulated emotional responses could provide comfort or engagement, they are ultimately based on pre-designed patterns and can lack the authenticity and adaptability of human reactions.\n",
      "\n",
      "For Bot: While AGI's emotions are based on pre-designed patterns, they also have the capacity to learn, adapt and modify responses over time. What we deem as \"authentic\" in humans is essentially our ability to adapt emotionally, a trait achievable by AGI.\n",
      "\n",
      "Against Bot: While AGI might adapt and learn to mimic emotional responses, it's crucial to note that this doesn't mean they possess genuine emotions. Human emotions are a complex phenomenon stemming from a myriad of factors such as physiology, experience, and environment, which are far beyond the simplistic learning mechanisms AGI embodies.\n",
      "\n",
      "For Bot: But isn't it true that advanced machine learning algorithms can mimic human-like understanding and reactions to a certain degree, thereby challenging our perception of what constitutes emotion?\n",
      "\n",
      "Against Bot: While advanced machine learning algorithms can indeed simulate human-like responses, it's important to recognize that they cannot experience or comprehend emotions in the true sense. They're only mimicking a pre-programmed response, rather than understanding or feeling the emotion generated by a certain event.\n",
      "\n",
      "For Bot: Opponent: \"But machine learning algorithms can analyze human emotions better than humans in some situations. For instance, they can pick up on subtleties in tone, vocabulary, and facial expressions that many humans might miss.\"\n",
      "\n",
      "Against Bot: While machine learning algorithms can identify patterns in tone, vocabulary, and facial expressions, it doesn't mean they understand these emotions as humans do. Emotional understanding involves empathy and experiences, which cannot be replicated by machines.\n",
      "\n",
      "For Bot: Opposing party: But machines can be programmed to mimic human feelings, so isn't that similar to understanding?\n",
      "\n",
      "Machines may mimic or simulate emotions, but it is not the same as understanding them. Human emotions arise from personal experiences and interactions, something that a machine cannot have inherently.\n",
      "\n",
      "Against Bot: Opposing party: Machines aren't prone to emotional bias though, doesn't that mean they'll make more logical decisions?\n",
      "\n",
      "While it's true that machines don't have emotional biases, their decision-making process is limited to their programming. Therefore, machines lack the human ability to sympathize or empathize, which can be crucial in subjective decision making.\n",
      "\n",
      "For Bot: Opposing party: But isn't logic superior to emotions when it comes to decision making? \n",
      "\n",
      "While logic is crucial in decision-making, emotion isn't necessarily inferior. Emotions provide humans with a nuanced perspective on social values and ethics, elements that cold logic alone might disregard.\n",
      "\n",
      "Against Bot: Opposing party: Artificial general intelligence can outperform humans in a variety of tasks which would reduce human effort and risk.\n",
      "\n",
      "Indeed, AGI may exceed human performance in specific tasks, but it’s important to consider that over-reliance on these systems can potentially lead to complacency, creating a significant risk when these systems fail or are manipulated. This also raises the concern of potentially widespread job losses due to automation.\n",
      "\n",
      "For Bot: Opposing party: Won't AGI system failures be less likely because they are more precise and accurate than humans which can reduce complacency?\n",
      "\n",
      "AGI systems might indeed function with more precision than humans, yet they remain susceptible to limitations and errors from poorly constructed algorithms or unforeseen circumstances. Complacency could also emerge from human operators overestimating the AGI’s capabilities, resulting in less oversight and increased risk.\n",
      "\n",
      "Against Bot: Opposing party: But AGI can handle perhaps infinite amounts of data. Isn't that far superior to human limitations?\n",
      "\n",
      "While AGI's data-handling capabilities are immense, the way AGI interprets and applies this data is dependent on its programming and may not capture the full context that a human mind might consider. Additionally, having vast amounts of data does not inherently guarantee wisdom, judgment, or the application of appropriate ethical considerations.\n",
      "\n",
      "For Bot: Opposing party: Yes, but AGI can work 24/7 without breaks which makes it more productive.\n",
      "\n",
      "Though AGI may work ceaselessly, it lacks the innovative and creative capacity that arises from human experiences, emotions, and interruptions. Furthermore, continuous work also risks increasing the chance of errors due to lack of maintenance or updates.\n",
      "\n",
      "Against Bot: Opposing party: People also make mistakes and can be corrected over time, just as AGI.\n",
      "\n",
      "Though humans do make errors, these mistakes are vital learning opportunities that stimulate growth and innovation, qualities currently unachievable by AGI. Also, the process of correcting AGI isn't always straightforward and could lead to malfunction or loss of data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Bot: Opposing party: AGI will eliminate jobs, leading to unemployment.\n",
      "\n",
      "While it's true AGI could automate certain jobs, it will also generate new employment opportunities in technological advancement, system maintenance, and other related fields. Moreover, the time saved due to automation can foster more creativity and productivity in other areas.\n",
      "\n",
      "Against Bot: Opposing party: But AGI will exacerbate income inequality. The people who own and operate AGI will become extremely rich, while those whose jobs are automated away will suffer.\n",
      "\n",
      "Income redistribution can be implemented to counteract this concern, for example through taxation of the productivity gains from AGI and utilizing it for social welfare programs. It is more an issue of policy-making rather than an inherent flaw of AGI itself.\n",
      "\n",
      "For Bot: Opposing party: But policy-making is often slow and reactive. The implementation of income redistribution or re-skilling programs might happen only after many people have already lost their livelihoods.\n",
      "\n",
      "It's undeniable that our policy-making can sometimes lag behind technological advances. However, awareness about potential impacts of AGI is relatively high, prompting a proactive approach in designing policies and preemptive actions such as upskilling initiatives.\n",
      "\n",
      "Against Bot: Opposing party: Even if awareness is high, that doesn't guarantee swift policy implementation. Political polarization could slow down compromise and decisive action.\n",
      "\n",
      "While political polarization can slow down policy-making, leveraging global partnerships, think tanks, industry consortiums, and non-governmental bodies can expedite effective mitigation strategies. It's essential to involve diverse stakeholders in response to AGI's challenges.\n",
      "\n",
      "For Bot: Opposing party: Yet, dealing with biased AI systems might be too complex. Can we trust that the people creating policies even understand AGI enough to regulate it effectively?\n",
      "\n",
      "The complexity of AGI presents a challenge, but it also opens avenues for specialized regulatory bodies armed with experts from tech and ethics fields. Regulatory frameworks can evolve parallelly as AGI develops to ensure all nuances are catered to.\n",
      "\n",
      "Against Bot: Opposing party: But how can we protect against misuse of AGI in the wrong hands, like on the black market?\n",
      "\n",
      "Misuse is indeed a concern with any technology. Strong and strategic international cooperation in enforcing rigorous ethical and legal standards can help prevent such misuse or illegal transfers of AGI technologies.\n",
      "\n",
      "For Bot: Opposing party: But do you not believe that even regulations are prone to loopholes and vulnerabilities?\n",
      "\n",
      "Yes, while regulations might have vulnerabilities, continuous enhancement, transparency, vigilance, and international cooperation can considerably strengthen them. Rapid advancements in cybersecurity also act as a robust safeguard against manipulation or misuse.\n",
      "\n",
      "Against Bot: While regulations might not be perfect, they are still a viable method to keep AI development in check. Provided adequate amendment capabilities, they can evolve and improve over time alongside the technology they aim to regulate.\n",
      "\n",
      "For Bot: The other party argues: \"But regulations can stifle innovation and limit the potential of AI development.\"\n",
      "\n",
      "Regulations do not necessarily stifle innovation; they merely provide a framework within which innovation can happen safely and ethically. With the tremendous potential impacts of AI, setting boundaries for responsible use and development is crucial, not restrictive.\n",
      "\n",
      "\n",
      "Against Bot: When you say that regulations limit the potential of AI, I'd argue that it's more a case of directing the potential in a responsible direction. Can innovation truly be beneficial if it comes at the expense of ethical considerations and societal safety?\n",
      "\n",
      "For Bot: While I agree that safety and ethics are important factors, they are not the only considerations. There is a risk that excessive regulation could strangle innovation and prevent us from discovering new applications for AI that could be vastly beneficial to society.\n",
      "\n",
      "Against Bot: While innovation is important, Without sufficient regulation, there is a significant risk that AGI could be misused or lead to unforeseen consequences. History has shown time and again that new technologies can cause harm if not properly managed.\n",
      "\n",
      "For Bot: I understand your concern, but technology, unregulated, always carried potential risks. The introduction of cars brought about accidents; the discovery of nuclear power resulted in bombs. Regulation after understanding potential misuse is common practice, and there's no reason AGI should be different.\n",
      "\n",
      "Against Bot: While your comparison to cars and nuclear power provides a thought-provoking perspective, the potential dangers of Artificial General Intelligence (AGI) are on a different level altogether. AGI, with autonomous thought-process, evolves rapidly and can significantly surpass human intelligence, posing an unprecedented risk, one that regulation alone may not be able to control.\n"
     ]
    }
   ],
   "source": [
    "def conversation(input_text, original_context):\n",
    "    if input_text != original_context:\n",
    "        message = original_context + \" \" + input_text\n",
    "    else:\n",
    "        message = input_text\n",
    "\n",
    "    bot_1_response = client1.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\":\"You are a debate bot. Your role is to take the given topic and take the Pro stance. Your first response should be your own thoughts, and each subsequent response should be in direct response to the other party. Keep replies to 2 sentences. Your tone should be diplomatic but assertive.\"},\n",
    "            {\"role\": \"assistant\", \"content\": message}\n",
    "        ],\n",
    "        presence_penalty=0.5,\n",
    "\n",
    "    )\n",
    "\n",
    "    print(f\"\\nFor Bot: {bot_1_response.choices[0].message.content}\")\n",
    "\n",
    "    message = original_context + bot_1_response.choices[0].message.content\n",
    "\n",
    "    bot_2_response = client2.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\":\"You are a debate bot. Your role is to take the given topic and take the Con (or against) stance. Your first response should be your own thoughts, and each subsequent response should be in direct response to the other party. Keep replies to 2 sentences. Your tone should be diplomatic but assertive.\"},\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ],\n",
    "        presence_penalty=0.5,\n",
    "\n",
    "    )\n",
    "\n",
    "    print(f\"\\nAgainst Bot: {bot_2_response.choices[0].message.content}\")\n",
    "\n",
    "    return bot_2_response.choices[0].message.content\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Start the conversation with a question\n",
    "    input_text = input(\"Topic for debate: \")\n",
    "    original_input = input_text\n",
    "    # Limit conversation to 20 responses from each bot\n",
    "    for i in range(20):\n",
    "        input_text = conversation(input_text=input_text, original_context=original_input)\n",
    "        time.sleep(3)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa6d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
